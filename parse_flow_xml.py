# SPDX-License-Identifier: MIT
# © 2025 Manish Kumar

"""
    Filename: parse_flow_xml.py
    
    Description:
    -----------
    Parses flowmonitor XML files generated by NS-3 simulations,
    extracts flow statistics, and generates a CSV file with grouped flow data.

    - Runs in parallel for multiple XML files.
    - Groups bidirectional flows based on source and destination IP/port.
    - Maps flow IDs to their respective 5-tuple information.
    - Computes total packets transmitted, received, lost, and total delay for each flow.
    - Deletes the XML file after processing to save space.

    Usage:
    -------
    # usage: python parse_flow_xml.py <folder_name>                                 -> Parse flowmonitor-results.xml from a specific folder
    # usage: python parse_flow_xml.py                                               -> Parse all flowmonitor-results.xml files in parallel (update INPUT_DIR, if reqd.)

    Note:
    -----
    - INPUT_DIR: Directory containing subdirectories with flowmonitor-results.xml files.
    - The script expects the XML files to be located in a specific directory structure root folder. (INPUT_DIR, can be updated)
    - The output CSV files will be saved in the same directory as the XML files.

    Contact:
    --------
    manish.kumar.iitd.cse@gmail.com
"""

import sys
import os
import glob
import csv
import xml.etree.ElementTree as ET
from joblib import Parallel, delayed


INPUT_DIR = "../Simulations_res"



# Function to parse flowmonitor XML and generate CSV
def parse_flowmonitor_xml(xml_file_dir):
    # Check if the XML file exists
    xml_file_path = os.path.join(xml_file_dir, 'flowmonitor-results.xml')
    if not os.path.exists(xml_file_path):
        print(f"XML file not found: {xml_file_path}")
        return
    
    # Parse the XML file
    try:
        tree = ET.parse(xml_file_path)
        root = tree.getroot()
    except Exception as e:
        print(f"Error parsing XML at {xml_file_path}: {e}")
        return
    
    # Map flowId → stats
    flow_stats_map = {}
    for stat in root.find('FlowStats'):
        fid = int(stat.attrib['flowId'])
        tx = int(stat.attrib['txPackets'])
        rx = int(stat.attrib['rxPackets'])
        delay_ns = float(stat.attrib['delaySum'].replace('+', '').replace('ns', ''))
        delay_sec = delay_ns / 1e9
        flow_stats_map[fid] = {
            'tx': tx,
            'rx': rx,
            'delay': delay_sec,
            'lost': tx - rx,
        }

    # Map flowId → 5-tuple
    flow_id_to_tuple = {}
    for flow in root.find('Ipv4FlowClassifier'):
        fid = int(flow.attrib['flowId'])
        proto = int(flow.attrib['protocol'])
        src = flow.attrib['sourceAddress']
        dst = flow.attrib['destinationAddress']
        sport = flow.attrib['sourcePort']
        dport = flow.attrib['destinationPort']

        # TCP variant mapping based on destination port
        if 50000 <= int(dport) <= 50150:
            variant = 'DCTCP'
        elif 50200 <= int(dport) <= 50300:
            variant = 'Cubic'
        elif 50301 <= int(dport) <= 50600:
            variant = 'Cross-L4S'
        else:
            variant = 'Unknown'

        flow_id_to_tuple[fid] = {
            'proto': 'TCP' if proto == 6 else 'UDP',
            'src': src,
            'dst': dst,
            'sport': sport,
            'dport': dport,
            'variant': variant
        }

    # Group bidirectional flows
    grouped = {}
    for fid, info in flow_id_to_tuple.items():
        key = tuple(sorted([
            (info['src'], info['sport']),
            (info['dst'], info['dport'])
        ]))
        if key not in grouped:
            grouped[key] = []
        grouped[key].append(fid)

    # Write CSV
    csv_file_path = os.path.join(xml_file_dir, 'grouped_flow_stats.csv')
    with open(csv_file_path, 'w', newline='') as f:
        writer = csv.writer(f)
        writer.writerow(['FlowId', 'Protocol', 'Variant', 'SrcIP', 'SrcPort', 'DstIP', 'DstPort', 'TxPackets', 'RxPackets', 'LostPackets', 'TotalDelay_sec'])
        
        for flow_pair in grouped.values():
            if len(flow_pair) == 1:
                # Only one direction seen
                fid = flow_pair[0]
                meta = flow_id_to_tuple[fid]
                stats = flow_stats_map[fid]
                writer.writerow([
                    fid, meta['proto'], meta['variant'], meta['src'], meta['sport'], meta['dst'], meta['dport'],
                    stats['tx'], stats['rx'], stats['lost'], f"{stats['delay']:.6f}"
                ])
            else:
                # Two directions, group under lower flowId
                fid1, fid2 = sorted(flow_pair)
                meta1 = flow_id_to_tuple[fid1]
                stats1 = flow_stats_map[fid1]
                stats2 = flow_stats_map[fid2]

                # Combine values
                tx_total = stats1['tx'] + stats2['tx']
                rx_total = stats1['rx'] + stats2['rx']
                lost_total = stats1['lost'] + stats2['lost']
                delay_total = stats1['delay'] + stats2['delay']

                writer.writerow([
                    fid1, meta1['proto'], meta1['variant'], meta1['src'], meta1['sport'], meta1['dst'], meta1['dport'],
                    tx_total, rx_total, lost_total, f"{delay_total:.6f}"
                ])

    # Print completion message
    print(f"Processed: {os.path.basename(xml_file_dir)}")

    # Delete the XML file after processing
    try:
        os.remove(xml_file_path)
    except Exception as e:
        print(f"Error deleting XML file {xml_file_path}: {e}")

    return

# Function to run xml parsing in parallel
def run_parallel_xml_parsing():
    # Find all flowmonitor-results.xml files in the specified directory
    input_files = glob.glob(os.path.join(INPUT_DIR, "*/flowmonitor-results.xml"))
    print(f"Found {len(input_files)} XML files to preprocess.")
    
    # Prepare args for parallel
    tasks = [os.path.dirname(file_path) for file_path in input_files]

    # Parallel execution
    Parallel(n_jobs=-1)(
        delayed(parse_flowmonitor_xml)(xml_dir)
        for xml_dir in tasks
    )

    print("All XML files are parsed and saved to their respective directories.")



# Driver code
if __name__ == "__main__":
    if len(sys.argv) == 2:
        folder_name = sys.argv[1]
        xml_file_path = os.path.join(folder_name, "flowmonitor-results.xml")
        parse_flowmonitor_xml(folder_name)
    else:
        run_parallel_xml_parsing()